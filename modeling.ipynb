{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_p.drop(columns = ['total_cost'])\n",
    "y = df_p['total_cost']\n",
    "X_train, y_train = train_test_split(X, y, stratify=y)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# setting up the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# def setup():\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#     df = pd.read_csv('data/Train.csv')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m#     X = df.drop(columns = ['total_cost'])\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#     y = df['total_cost']\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[39m# X_train, y_train = train_test_split(X, y, stratify=y)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m X \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mtotal_cost\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtotal_cost\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m X_train, y_train \u001b[39m=\u001b[39m train_test_split(X, y, stratify\u001b[39m=\u001b[39my)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# setting up the model\n",
    "# def setup():\n",
    "#     df = pd.read_csv('data/Train.csv')\n",
    "#     X = df.drop(columns = ['total_cost'])\n",
    "#     y = df['total_cost']\n",
    "    # X_train, y_train = train_test_split(X, y, stratify=y)\n",
    "\n",
    "X = df.drop(columns = ['total_cost'])\n",
    "y = df['total_cost']\n",
    "X_train, y_train = train_test_split(X, y, stratify=y)\n",
    "X_train.head()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "to be completed"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# to be filled with numerical column names \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# numercial variable scaling \u001b[39;00m\n\u001b[1;32m      4\u001b[0m numerical_columns \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m num_pipeline \u001b[39m=\u001b[39m Pipeline([\n\u001b[1;32m      7\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mnum_scaler\u001b[39m\u001b[39m'\u001b[39m, StandardScaler())\n\u001b[1;32m      8\u001b[0m ])\n\u001b[1;32m     10\u001b[0m preprocessor \u001b[39m=\u001b[39m ColumnTransformer([\n\u001b[1;32m     11\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mnum_processor\u001b[39m\u001b[39m'\u001b[39m, num_pipeline, numerical_columns)\n\u001b[1;32m     12\u001b[0m ])\n\u001b[1;32m     14\u001b[0m preprocessor\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# to be filled with numerical column names \n",
    "# numercial variable scaling \n",
    "\n",
    "numerical_columns = []\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('num_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_processor', num_pipeline, numerical_columns)\n",
    "])\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# baseline model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m lin_reg  \u001b[39m=\u001b[39m LinearRegression()\n\u001b[0;32m----> 3\u001b[0m lin_reg\u001b[39m.\u001b[39mfit(X_train , y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "lin_reg  = LinearRegression()\n",
    "lin_reg.fit(X_train , y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessor variables (with or without scaling)\n",
    "preprocessor_with_scaler = Pipeline([\n",
    "    ('num_scaler', StandardScaler()),\n",
    "])\n",
    "preprocessor_without_scaler = Pipeline([\n",
    "    ('identity_transform', FunctionTransformer(func=lambda x: x))\n",
    "])\n",
    "\n",
    "# build model pipeline, insert further models\n",
    "pipelines = {\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('preprocessor', preprocessor_with_scaler),\n",
    "        ('model', LogisticRegression())\n",
    "    ]),\n",
    "    'DecisionTreeClassifier': Pipeline([\n",
    "        ('preprocessor', preprocessor_without_scaler),\n",
    "        ('model', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'KNearestNeighbor': Pipeline([\n",
    "        ('preprocessor', preprocessor_without_scaler),\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'RandomForestClassifier': Pipeline([\n",
    "        ('preprocessor', preprocessor_without_scaler),\n",
    "        ('model', RandomForestClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create parameters for each model\n",
    "logreg_parameter_grid = {\n",
    "    'model__penalty': ['l1', 'l2', 'none'],\n",
    "    'model__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'model__solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'model__max_iter': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    'model__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "dectree_parameter_grid = {\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'model__min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'model__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'model__max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "    'model__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "knn_parameter_grid = {\n",
    "    'model__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'model__weights': [None, 'uniform', 'distance'],\n",
    "    'model__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'model__leaf_size': [30, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500],\n",
    "    'model__p': [1, 2],\n",
    "    'model__metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "rf_parameter_grid = {\n",
    "    'model__n_estimators': [100, 300, 500, 700, 1000],\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__max_depth': [3, 4, 5, 6, 7],\n",
    "    'model__min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'model__min_samples_leaf': [1, 2, 3, 4, 6, 8, 10, 12],\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ve_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
